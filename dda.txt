If your source dataset is in Hive with columns named "rollnum," "hobby_new1," "hobby_new2," "hobby_new3," "hobby_old1," "hobby_old2," and "hobby_old3," you can still achieve the task by first transforming the data into the appropriate format and then finding the common hobbies. Here's a PySpark recipe for that:

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import concat_ws, split, array_intersect

# Create a Spark session
spark = SparkSession.builder.appName("HobbyIntersection").enableHiveSupport().getOrCreate()

# Read the Hive dataset into a DataFrame
df = spark.sql("SELECT rollnum, CONCAT_WS(', ', hobby_new1, hobby_new2, hobby_new3) AS new_hobbies, CONCAT_WS(', ', hobby_old1, hobby_old2, hobby_old3) AS old_hobbies FROM your_hive_table")

# Split the comma-separated hobbies into arrays
df = df.withColumn("NewHobbies", split(col("new_hobbies"), ", "))
df = df.withColumn("OldHobbies", split(col("old_hobbies"), ", "))

# Calculate the intersection of new and old hobbies
df = df.withColumn("CommonHobbies", array_intersect(col("NewHobbies"), col("OldHobbies")))

# Show the result
df.show(truncate=False)

# Stop the Spark session
spark.stop()
```

In this code:
- We use `enableHiveSupport()` to enable Hive integration in Spark.
- We read the data from your Hive table into a DataFrame.
- We concatenate the columns "hobby_new1," "hobby_new2," and "hobby_new3" into a single column "new_hobbies," and similarly for old hobbies.
- We split the comma-separated hobby strings into arrays using `split`.
- Then, we calculate the intersection of the arrays of new and old hobbies using `array_intersect`.
- The result DataFrame will contain the common hobbies for each student.

Replace `"your_hive_table"` with the actual name of your Hive table in the `spark.sql` statement and make sure your Spark cluster has access to the Hive metastore.