
from fuzzywuzzy import fuzz

def load_data(file_path):
    with open(file_path, 'r') as file:
        return [line.strip() for line in file]

def find_matching_employee(transaction_name, employee_names):
    best_match = None
    max_similarity = 0

    for employee_name in employee_names:
        similarity = fuzz.ratio(transaction_name, employee_name)
        if similarity > max_similarity:
            max_similarity = similarity
            best_match = employee_name

    return best_match if max_similarity >= 80 else None  # Adjust the similarity threshold as needed

def detect_fraud(client_transactions, employee_names):
    potential_fraud = []

    for transaction in client_transactions:
        counter_party_name = transaction['counter_party_full_name']
        matching_employee = find_matching_employee(counter_party_name, employee_names)

        if matching_employee:
            potential_fraud.append({
                'client_transaction': transaction,
                'matching_employee': matching_employee
            })

    return potential_fraud

if __name__ == "__main__":
    # Load employee and client transaction data
    employees = load_data('employee.txt')  # Replace 'employee.txt' with the actual file path
    client_transactions = load_data('client_transactions.txt')  # Replace 'client_transactions.txt'

    # Detect potential fraud using fuzzy matching
    potential_fraud_data = detect_fraud(client_transactions, employees)

    # Print or handle potential fraud data
    if potential_fraud_data:
        print("Potential fraud transactions:")
        for data in potential_fraud_data:
            print(f"Transaction: {data['client_transaction']}, Matching Employee: {data['matching_employee']}")
    else:
        print("No potential fraud detected.")









---------------------------------------------------------------------------------------------------------------------------------------------------


this is a new section for multi emp under same name 

employee_name_map = {}
for index, row in df_employee.iterrows():
    key = row['full_name']
    if key not in employee_name_map:
        employee_name_map[key] = []
    employee_name_map[key].append(row['emp_id'])


--------


def get_emp_ids(full_name):
    return employee_name_map.get(full_name, [])



____________
explode

# Apply the function to create a new column 'emp_ids' in the transaction dataframe
df_transaction['emp_ids'] = df_transaction['full_name'].apply(get_emp_ids)

# Explode the dataframe to create separate rows for each matched employee
df_transaction_exploded = df_transaction.explode('emp_ids')

# Merge with employee details to get additional information
result_df = pd.merge(df_transaction_exploded, df_employee, left_on='emp_ids', right_on='emp_id', how='left')

# Display the result
print(result_df[['txn_id', 'full_name_x', 'emp_ids', 'emp_id', 'full_name_y']])





-----------------------

fname match mulit return using series 


import pandas as pd

def add_match_values(row, fname_dict, mname_dict, lname_dict):
    # Add columns for first_name match_value, mid_name match_value, and last_name match_value
    return pd.Series([
        fname_dict.get(row['first_name'], None),
        mname_dict.get(row['mid_name'], None),
        lname_dict.get(row['last_name'], None)
    ], index=['first_name_match_value', 'mname_match_value', 'lname_match_value'])

# Example usage:
# Assuming you have a DataFrame named 'my_dataframe' with columns first_name, mid_name, and last_name
# and dictionaries fname_dict, mname_dict, and lname_dict

my_dataframe = pd.DataFrame({
    'first_name': ['John', 'Alice', 'Bob'],
    'mid_name': ['Doe', 'Mae', 'E'],
    'last_name': ['Smith', 'Johnson', 'Lee']
})

fname_dict = {'John': 1, 'Alice': 2, 'Bob': 3}
mname_dict = {'Doe': 4, 'Mae': 5, 'E': 6}
lname_dict = {'Smith': 7, 'Johnson': 8, 'Lee': 9}

# Apply the function to each row
result_dataframe = my_dataframe.apply(lambda row: add_match_values(row, fname_dict, mname_dict, lname_dict), axis=1)

print(pd.concat([my_dataframe, result_dataframe], axis=1))







**Epic: Python Migration from 3.7 to 3.10**

**Epic Description:**
This epic entails the comprehensive migration of our firm's codebase from Python 3.7 to Python 3.10. The migration aims to leverage the latest language features, optimizations, and improvements offered by Python 3.10, ensuring codebase modernization, enhanced performance, and compatibility with future Python releases. The migration process will be conducted systematically, addressing discovery, dependency resolution, syntax conversion, performance optimization, testing, documentation, and rollout phases.

**Stories:**

**1. Discovery and Assessment:**
- **JIRA ID:** PM-01
- **Description:** Conduct a detailed analysis of the existing codebase to identify Python 3.7-specific dependencies, syntax, and libraries.
- **Tasks:**
  - Utilize automated tools to detect Python 3.7 deprecated features and modules.
  - Review third-party dependencies for compatibility with Python 3.10.
  - Document potential compatibility issues, deprecated features, and areas requiring modification.

**2. Dependency Resolution and Management:**
- **JIRA ID:** PM-02
- **Description:** Address dependencies incompatible with Python 3.10 and manage library updates.
- **Tasks:**
  - Evaluate alternative libraries for deprecated dependencies.
  - Update existing dependencies to versions compatible with Python 3.10.
  - Verify the compatibility of dependencies with the upgraded Python version through thorough testing.

**3. Syntax Conversion and Modernization:**
- **JIRA ID:** PM-03
- **Description:** Convert Python 3.7 syntax to Python 3.10-compatible syntax and implement modernization strategies.
- **Tasks:**
  - Replace deprecated syntax with updated equivalents.
  - Implement new language features introduced in Python 3.10.
  - Conduct unit tests and static code analysis to ensure syntax conversion does not introduce regressions.

**4. Performance Optimization and Enhancement:**
- **JIRA ID:** PM-04
- **Description:** Identify and optimize performance bottlenecks in the codebase during the migration process.
- **Tasks:**
  - Profile critical sections of the codebase to identify performance bottlenecks.
  - Implement optimizations leveraging Python 3.10 features and improvements.
  - Benchmark performance improvements against baseline metrics and establish performance targets.

**5. Comprehensive Testing and Validation:**
- **JIRA ID:** PM-05
- **Description:** Execute extensive testing to validate the functionality, stability, and performance of the migrated codebase.
- **Tasks:**
  - Develop comprehensive test suites covering all aspects of application functionality.
  - Execute unit tests, integration tests, and regression tests.
  - Conduct compatibility testing across different environments, platforms, and edge cases.

**6. Documentation, Training, and Knowledge Sharing:**
- **JIRA ID:** PM-06
- **Description:** Document the migration process, provide training, and facilitate knowledge sharing to empower the development team.
- **Tasks:**
  - Create detailed documentation outlining the steps involved in the Python 3.7 to 3.10 migration.
  - Provide training sessions and workshops for developers on Python 3.10 features and migration best practices.
  - Foster a collaborative environment for knowledge sharing and problem-solving among team members.

**7. Rollout Plan, Deployment, and Post-Migration Support:**
- **JIRA ID:** PM-07
- **Description:** Plan and execute the rollout of the migrated codebase into production environments, ensuring a seamless transition and providing post-migration support.
- **Tasks:**
  - Develop a comprehensive rollout plan with rollback strategies and contingency measures.
  - Coordinate with stakeholders for deployment scheduling and communication.
  - Monitor system performance post-migration, address any issues promptly, and provide ongoing support to ensure stability.

This comprehensive set of stories outlines a structured approach to the Python migration process, covering all essential phases and tasks required for a successful transition to Python 3.10. Each story is broken down into specific tasks to ensure clarity, accountability, and efficient execution.